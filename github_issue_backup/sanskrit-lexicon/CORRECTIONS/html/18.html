<!DOCTYPE html>
<html class='' lang='en'>
<head prefix='og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# object: http://ogp.me/ns/object# article: http://ogp.me/ns/article# profile: http://ogp.me/ns/profile#'>
<meta http-equiv='content-type' content='text/html; charset=UTF-8'>
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge'>
<meta http-equiv='Content-Language' content='en'>
<title>sanskrit-lexicon/CORRECTIONS/18</title>
<link href='github-c486157afcc5f58155a921bc675afb08733fbaa8dcf39ac2104d3.css' media='all' rel='stylesheet'>
<link href='github2-da2e842cc3f0aaf33b727d0ef034243c12ab008fd09b24868b97.css' media='all' rel='stylesheet'>
<meta http-equiv='x-pjax-version' content='4426702614c8182f33d1780ad1169662'>
</head>
<body class='logged_in  env-production windows vis-public'>
<h1 align='center'><a href='https://github.com/sanskrit-lexicon/CORRECTIONS/issues/18' target='_blank'>Klassische deutsche Rechtschreibung</h1><hr/><div id="#issue-45952366" class="comment previewable-edit timeline-comment js-comment js-task-list-container owner-comment current-user" data-body-version="3d69eb2502aec4738da37c0867d635da">
  <div class="timeline-comment-header ">
  <div class="timeline-comment-header-text">
    <strong>
      <a href="https://github.com/gasyoun" class="author">gasyoun</a>
    </strong>
    commented on 
    <a href="#issue-45952366" class="timestamp">
      <time>2014-10-16 06:18:25</time>
    </a>
  </div>
</div><div class="edit-comment-hide">
      <div class="comment-body markdown-body markdown-format js-comment-body">
          <p><strong><a href="https://github.com/funderburkjim" target="_blank">@funderburkjim</a></strong>
Per <a href="https://github.com/sanskrit-lexicon/CORRECTIONS/issues/8#issuecomment-59296504">https://github.com/sanskrit-lexicon/CORRECTIONS/issues/8#issuecomment-59296504</a> request.
<code>Marcis - do you have a 'German word list' (a digital German dictionary or word list) that might be used to kick out candidates for mis-spelled German words in PW, PWG , CSS ?</code></p>
<p>No, I do not have, but yes, let's start the trip. I found exactly what we are looking for, German from year 1901, a list of 235298 words <a href="http://extensions.libreoffice.org/extension-center/german-de-de-1901-old-spelling-dictionaries">German old spelling dictionaries</a> - Klassische deutsche Rechtschreibung in .OXT format.</p>
<p>The encoding is broken, similar to <a href="http://stackoverflow.com/questions/1344692/i-need-help-fixing-broken-utf8-encoding">http://stackoverflow.com/questions/1344692/i-need-help-fixing-broken-utf8-encoding</a>. Emailed Bjoern Jacke, Franz Michael Baumann about the used encoding.
Reply:</p>
<pre><code>im von igerman98 generierten hunspell wörterbuch ist iso8895-1 die codierung.</code></pre>
<p>So <a href="http://stackoverflow.com/questions/3990700/iso-8895-1-to-xml-acceptable-utf-8">http://stackoverflow.com/questions/3990700/iso-8895-1-to-xml-acceptable-utf-8</a> should work.
We do not need to go <a href="http://askubuntu.com/questions/72099/how-to-install-a-libreoffice-dictionary-spelling-check-thesaurus">http://askubuntu.com/questions/72099/how-to-install-a-libreoffice-dictionary-spelling-check-thesaurus</a>, because <a href="https://www.sublimetext.com/forum/viewtopic.php?f=3&t=6127">https://www.sublimetext.com/forum/viewtopic.php?f=3&t=6127</a> did the job.</p>
<p>The journey starts at <a href="https://github.com/sanskrit-lexicon/CORRECTIONS/tree/master/dict-de_de-1901_oldspell_2014-02-21">https://github.com/sanskrit-lexicon/CORRECTIONS/tree/master/dict-de_de-1901_oldspell_2014-02-21</a> - I hope I'll have an UTF-8 compitable list in a short while.</p>
  </div>
  </div>
  </div>
  <br/>
<div id="#issuecomment-60542543" class="comment previewable-edit timeline-comment js-comment js-task-list-container owner-comment current-user" data-body-version="3d69eb2502aec4738da37c0867d635da">
  <div class="timeline-comment-header ">
  <div class="timeline-comment-header-text">
    <strong>
      <a href="https://github.com/funderburkjim" class="author">funderburkjim</a>
    </strong>
    commented on 
    <a href="#issuecomment-60542543" class="timestamp">
      <time>2014-10-27 01:55:09</time>
    </a>
  </div>
</div><div class="edit-comment-hide">
      <div class="comment-body markdown-body markdown-format js-comment-body">
          <p>See <a href="https://dl.dropboxusercontent.com/u/29859999/ccs_all1.zip">https://dl.dropboxusercontent.com/u/29859999/ccs_all1.zip</a></p>
<p>There happens to be a Python module pyenchant (<a href="https://pythonhosted.org/pyenchant/">https://pythonhosted.org/pyenchant/</a>) which allows easy access to xspell compatible dictionaries, such as de_DE_OLDSPELL .  Hurray!</p>
<p>It seems to give good results, and there is appears to be no need for concern re iso8895-1 coding.</p>
<p>Here, in short, is how this dictionary has been used thus far:</p>
<ol>
<li>Start with ccs.xml</li>
<li>Categorize words appearing in the body of each record into one of 4 types, based upon the markup:
a. &quot;D&quot; = Devanagari, coded as slp1
b. &quot;I&quot;  = Italicized words (which contain no digit)
c. &quot;O&quot; = Other words (which contain no digit)
d. &quot;N&quot; = Non-devanagari words which contain a digit (most are Anglicized Sanskrit coding of IAST)</li>
<li>Write out file of all such words, counting the frequency (all.txt,). The format is:
<pre><code>&lt;word&gt;:&lt;count&gt;:&lt;code&gt;:X   (&lt;code&gt; is D,I,O,N) (X means not-explained)</code></pre>
<p>There are  62940 lines in all.txt.</p></li>
<li>Explain the German words using pyenchant interface to de_DE_OLDSPELL.
This applies only to codes I or O.
The result is all1.txt.
Here is a summary using prettytable module:
<pre><code>
Summary for words of type 'D'
+--------+-------+
| Status |  Freq |
+--------+-------+
| Total  | 36999 |
| X      | 36999 |
+--------+-------+
Summary for words of type 'I'
+-------------------+------+
| Status            | Freq |
+-------------------+------+
| Total             | 2284 |
| X                 |  794 |
| OK=de_DE_OLDSPELL | 1490 |
+-------------------+------+
Summary for words of type 'O'
+-------------------+-------+
| Status            |  Freq |
+-------------------+-------+
| Total             | 23204 |
| X                 |  5648 |
| OK=de_DE_OLDSPELL | 17556 |
+-------------------+-------+
Summary for words of type 'N'
+--------+------+
| Status | Freq |
+--------+------+
| Total  |  453 |
| X      |  453 |
+--------+------+</code></pre></li>
</ol>
<pre><code>

I am imagining that eventually all words will be explained or corrected by as yet unknown steps, leading to all2.txt ... alldone.txt

One can easily filter all1.txt on subcategories  (e.g. :[IO]:  for the supposed German words.)

I'm sure some of those 5648 unexplained 'O' German words can be explained as some kinds of
compounds.  There may be a way, that I don't know, to do this with enchant.  Absent that, maybe Marcis can suggest some patterns of German.

The choice of de_DE_OLDSPELL was an excellent one.  For instance, the enchant logic properly
interpreted the 'suffix' information present in de_DE_OLDSPELL.dic and de_DE_OLDSPELL.aff -- not a trivial task.</code></pre>
  </div>
  </div>
  </div>
  <br/>
<div id="#issuecomment-60612686" class="comment previewable-edit timeline-comment js-comment js-task-list-container owner-comment current-user" data-body-version="3d69eb2502aec4738da37c0867d635da">
  <div class="timeline-comment-header ">
  <div class="timeline-comment-header-text">
    <strong>
      <a href="https://github.com/gasyoun" class="author">gasyoun</a>
    </strong>
    commented on 
    <a href="#issuecomment-60612686" class="timestamp">
      <time>2014-10-27 15:32:50</time>
    </a>
  </div>
</div><div class="edit-comment-hide">
      <div class="comment-body markdown-body markdown-format js-comment-body">
          <p>Jim, it's a miracle indeed. I only wonder if we can get the contexts or make it linkable. For that I would need to know what is the header of the wrong word I have found. Otherwise I checked <a href="http://www.sanskrit-lexicon.uni-koeln.de/scans/CCSScan/2014/web/webtc2/index.php">http://www.sanskrit-lexicon.uni-koeln.de/scans/CCSScan/2014/web/webtc2/index.php</a> for <code>Wgschaffen</code> and of course it's wrong. Can I ask you to give me only <code>O</code> that are not <code>OK=de_DE_OLDSPELL</code>? Excel sorting skills when I'm on the way on my laptop are miserable. I see literary hundreds of mistakes, that I can fix even without looking in the book. But this dictionary is not top priority so let's get back to PWK, PWG, MW, SCH, VCP. This I'll think about how to make it with less possible blood on my spare time after we have some good news on MW verb lexnorm update.</p>
<pre><code>wssenskundig    1   O   X
Wsserkrug   1   O   X
wunderreich 1   O   X
Wunderthat  1   O   X
Wunderthäter    1   O   X
wunderthätig    2   O   X
Wundmachen  1   O   X
wunschentsprechend  3   O   X
wunscherfüllend 2   O   X
Wunschgeborene  1   O   X
wunschgeschirrt 1   O   X
wunschgewährend 2   O   X
Wurfgeschoss    4   O   X
Wurzelschooß    1   O   X
Wurßcheibe  2   O   X</code></pre>
<p>Many are totally ok, like <code>Wunschgeborene</code> and I wonder why they are not marked as <code>OK</code>, still we have found <code>Wsserkrug</code>, so it's a good way to clean up in batch mode old German texts. And that is exactly our case.</p>
  </div>
  </div>
  </div>
  <br/>
</body></html>